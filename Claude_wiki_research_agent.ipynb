{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6j1SSrM80IjMEaPr6fwiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hfarazul/Claude-Tools-Exercises/blob/main/Claude_wiki_research_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic\n",
        "!pip install wikipedia\n",
        "\n",
        "import anthropic\n",
        "import os\n",
        "import wikipedia\n",
        "\n",
        "client = anthropic.Anthropic( # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "api_key=\"your-api-key\",\n",
        ")\n",
        "\n",
        "os.makedirs('output', exist_ok=True)\n",
        "open('output/research_reading.md', 'w').close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OIvDRVE_Dx3",
        "outputId": "044cb7a3-e955-4009-a38f-39988e16aa1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FGhwHnUeodS3"
      },
      "outputs": [],
      "source": [
        "def generate_wikipedia_reading_list(research_topic, article_titles):\n",
        "    wikipedia_articles = []\n",
        "    for t in article_titles:\n",
        "        results = wikipedia.search(t)\n",
        "        try:\n",
        "            page = wikipedia.page(results[0])\n",
        "            title = page.title\n",
        "            url = page.url\n",
        "            wikipedia_articles.append({\"title\": title, \"url\": url})\n",
        "        except:\n",
        "            continue\n",
        "    add_to_research_reading_file(wikipedia_articles, research_topic)\n",
        "\n",
        "def add_to_research_reading_file(articles, topic):\n",
        "    with open(\"output/research_reading.md\", \"a\", encoding=\"utf-8\") as file:\n",
        "        file.write(f\"## {topic} \\n\")\n",
        "        for article in articles:\n",
        "            title = article[\"title\"]\n",
        "            url = article[\"url\"]\n",
        "            file.write(f\"* [{title}]({url}) \\n\")\n",
        "        file.write(f\"\\n\\n\")\n",
        "\n",
        "\n",
        "generate_wikipedia_reading_list_tool = {\n",
        "    \"name\": \"generate_wikipedia_reading_list\",\n",
        "    \"description\": \"Generates a list of Wikipedia articles and their URLs based on a provided list of potential article titles for a given research topic.\",\n",
        "    \"input_schema\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"topic\": {\"type\": \"string\", \"description\": \"The research topic.\"},\n",
        "            \"article_titles\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"A list of potential Wikipedia article titles.\"}\n",
        "        },\n",
        "        \"required\": [\"topic\", \"article_titles\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_research_help(topic, num_articles=3):\n",
        "    prompt = f\"\"\"You are a research assistant helping me gather information on the topic of \"{topic}\". I need you to generate a list of {num_articles} potential Wikipedia article titles related to this topic that I could read.\n",
        "\n",
        "However, I want you to use a specific tool to generate the list of article titles. You must respond with a JSON object in the following format:\n",
        "\n",
        "{{\n",
        "    \"tool\": \"generate_wikipedia_reading_list\",\n",
        "    \"topic\": \"<research_topic>\",\n",
        "    \"article_titles\": [\"<article_title_1>\", \"<article_title_2>\", ...]\n",
        "}}\n",
        "\n",
        "Replace <research_topic> with the research topic \"{topic}\" and provide a list of {num_articles} potential Wikipedia article titles in the \"article_titles\" field.\n",
        "\n",
        "You should not provide the article titles directly in your response. Instead, you must use the JSON format above to invoke the \"generate_wikipedia_reading_list\" tool and generate the list of potential article titles.\n",
        "\n",
        "Please respond with the JSON object now to invoke the tool and generate the list of potential article titles.\n",
        "\"\"\"\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-sonnet-20240229\",\n",
        "        system=\"You have access to tools, but only use them when it's helpful. If a tool is not required, respond as normal\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        tools=[generate_wikipedia_reading_list_tool],\n",
        "        max_tokens=2000,\n",
        "    )\n",
        "\n",
        "    if response.stop_reason == \"tool_use\":\n",
        "        tool_use = response.content[-1]\n",
        "        tool_name = tool_use.name\n",
        "        tool_input = tool_use.input\n",
        "\n",
        "        if tool_name == \"generate_wikipedia_reading_list\":\n",
        "            generate_wikipedia_reading_list(tool_input[\"topic\"], tool_input[\"article_titles\"])\n",
        "            print(f\"tool used\")\n",
        "    else:\n",
        "        print(f\"Claude did not use the tool. Response: {response.content[0].text}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_research_help(\"animal consciousness\", num_articles=3)\n",
        "!cat output/research_reading.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ypSi8I_cwE",
        "outputId": "ee0f2c68-38ec-4f00-fb5d-6da40b24a212"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tool used\n",
            "## Pirates across the world \n",
            "* [Piracy](https://en.wikipedia.org/wiki/Piracy) \n",
            "* [Piracy](https://en.wikipedia.org/wiki/Piracy) \n",
            "* [History of the Pittsburgh Pirates](https://en.wikipedia.org/wiki/History_of_the_Pittsburgh_Pirates) \n",
            "* [Barbary pirates](https://en.wikipedia.org/wiki/Barbary_pirates) \n",
            "* [Pirate code](https://en.wikipedia.org/wiki/Pirate_code) \n",
            "\n",
            "\n",
            "## history of hawaii \n",
            "* [Hawaii](https://en.wikipedia.org/wiki/Hawaii) \n",
            "* [Ancient Hawaii](https://en.wikipedia.org/wiki/Ancient_Hawaii) \n",
            "* [Hawaiian Kingdom](https://en.wikipedia.org/wiki/Hawaiian_Kingdom) \n",
            "* [Hawaiian Islands](https://en.wikipedia.org/wiki/Hawaiian_Islands) \n",
            "* [Hawaiian sovereignty movement](https://en.wikipedia.org/wiki/Hawaiian_sovereignty_movement) \n",
            "* [Hawaiian Renaissance](https://en.wikipedia.org/wiki/Hawaiian_Renaissance) \n",
            "\n",
            "\n",
            "## animal consciousness \n",
            "* [Animal consciousness](https://en.wikipedia.org/wiki/Animal_consciousness) \n",
            "* [Philosophy of mind](https://en.wikipedia.org/wiki/Philosophy_of_mind) \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}